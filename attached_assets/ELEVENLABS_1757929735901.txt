

## üéØ ElevenLabs Implementierungsplan

### **Phase 1: Setup & Basic Integration (1-2 Stunden)**

#### 1.1 API-Setup & Environment
```bash
# Environment Variable hinzuf√ºgen
# In Replit Secrets:
ELEVENLABS_API_KEY=your_api_key_here
```

#### 1.2 ElevenLabs Service erstellen
```typescript
// client/src/services/elevenLabsVoice.ts
export class ElevenLabsVoiceManager {
  private apiKey: string;
  private baseURL = 'https://api.elevenlabs.io/v1';
  private voiceId = 'pNInz6obpgDQGcFmaJgB'; // Deutsche Stimme
  
  constructor() {
    this.apiKey = import.meta.env.VITE_ELEVENLABS_API_KEY;
    if (!this.apiKey) {
      throw new Error('ElevenLabs API Key nicht gefunden');
    }
  }
  
  async generateSpeech(text: string): Promise<ArrayBuffer> {
    const response = await fetch(`${this.baseURL}/text-to-speech/${this.voiceId}`, {
      method: 'POST',
      headers: {
        'Accept': 'audio/mpeg',
        'Content-Type': 'application/json',
        'xi-api-key': this.apiKey
      },
      body: JSON.stringify({
        text,
        model_id: "eleven_multilingual_v2",
        voice_settings: {
          stability: 0.75,
          similarity_boost: 0.85,
          style: 0.0,
          use_speaker_boost: true
        }
      })
    });
    
    if (!response.ok) {
      throw new Error(`ElevenLabs API Error: ${response.status}`);
    }
    
    return response.arrayBuffer();
  }
  
  async playAudio(audioBuffer: ArrayBuffer): Promise<void> {
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const decodedAudio = await audioContext.decodeAudioData(audioBuffer);
    
    const source = audioContext.createBufferSource();
    source.buffer = decodedAudio;
    source.connect(audioContext.destination);
    source.start();
    
    return new Promise(resolve => {
      source.onended = () => resolve();
    });
  }
  
  async speak(text: string): Promise<void> {
    console.log('üé§ ElevenLabs TTS:', text);
    const audioBuffer = await this.generateSpeech(text);
    await this.playAudio(audioBuffer);
  }
}
```

#### 1.3 Test-Integration
```typescript
// client/src/components/Navigation/VoiceTestPanel.tsx
import { useState } from 'react';
import { ElevenLabsVoiceManager } from '../../services/elevenLabsVoice';

export function VoiceTestPanel() {
  const [voiceManager] = useState(() => new ElevenLabsVoiceManager());
  const [isPlaying, setIsPlaying] = useState(false);
  
  const testInstructions = [
    "Links abbiegen",
    "Auf Geilenkirchener Stra√üe geradeaus fahren",
    "Rechts abbiegen auf Fasanenstra√üe",
    "Sie haben Ihr Ziel erreicht"
  ];
  
  const handleTest = async (instruction: string) => {
    setIsPlaying(true);
    try {
      await voiceManager.speak(instruction);
    } catch (error) {
      console.error('Voice test failed:', error);
    } finally {
      setIsPlaying(false);
    }
  };
  
  return (
    <div className="bg-white p-4 rounded-lg shadow">
      <h3 className="text-lg font-semibold mb-4">üé§ ElevenLabs Voice Test</h3>
      
      {testInstructions.map((instruction, index) => (
        <button
          key={index}
          onClick={() => handleTest(instruction)}
          disabled={isPlaying}
          className="block w-full p-2 mb-2 text-left bg-blue-50 hover:bg-blue-100 rounded"
        >
          ‚ñ∂Ô∏è {instruction}
        </button>
      ))}
      
      {isPlaying && <p className="text-blue-600">üîä Sprachausgabe l√§uft...</p>}
    </div>
  );
}
```

### **Phase 2: Deutsche Navigation-Optimierung (2-3 Stunden)**

#### 2.1 Deutsche Text-Optimierung
```typescript
// client/src/services/germanTextOptimizer.ts
export class GermanTextOptimizer {
  
  optimizeForSpeech(text: string): string {
    return text
      // Stra√üennamen-Optimierung
      .replace(/stra√üe/gi, 'Stra√üe')
      .replace(/platz/gi, 'Platz')
      .replace(/weg/gi, 'Weg')
      .replace(/gasse/gi, 'Gasse')
      
      // Pausen f√ºr bessere Verst√§ndlichkeit
      .replace(/(Stra√üe|Platz|Weg|Gasse)/g, '$1,')
      .replace(/(\d+)\s*(Meter|meter)/gi, '$1 Meter,')
      
      // Zahlen ausschreiben
      .replace(/\b1\b/g, 'eins')
      .replace(/\b2\b/g, 'zwei')
      .replace(/\b3\b/g, 'drei')
      .replace(/\b100\b/g, 'hundert')
      .replace(/\b200\b/g, 'zweihundert')
      .replace(/\b500\b/g, 'f√ºnfhundert')
      
      // Navigation-spezifische Verbesserungen
      .replace(/\bbei\b/g, 'bei der')
      .replace(/\bin\b/g, 'in die')
      .replace(/\bauf\b/g, 'auf die');
  }
  
  addNavigationEmotion(text: string, type: 'direction' | 'warning' | 'arrival'): string {
    switch (type) {
      case 'direction':
        return text; // Neutral
      case 'warning':
        return `Achtung: ${text}`;
      case 'arrival':
        return `${text}. Herzlichen Gl√ºckwunsch!`;
      default:
        return text;
    }
  }
}
```

#### 2.2 Erweiterte Voice Manager
```typescript
// client/src/services/elevenLabsVoice.ts (erweitert)
import { GermanTextOptimizer } from './germanTextOptimizer';

export class EnhancedElevenLabsVoice extends ElevenLabsVoiceManager {
  private optimizer = new GermanTextOptimizer();
  private audioCache = new Map<string, ArrayBuffer>();
  
  async speakNavigation(
    instruction: string, 
    type: 'direction' | 'warning' | 'arrival' = 'direction'
  ): Promise<void> {
    const optimizedText = this.optimizer.optimizeForSpeech(instruction);
    const emotionalText = this.optimizer.addNavigationEmotion(optimizedText, type);
    
    // Cache-Check
    const cacheKey = this.hashText(emotionalText);
    if (this.audioCache.has(cacheKey)) {
      console.log('üéØ Cache Hit:', emotionalText);
      await this.playAudio(this.audioCache.get(cacheKey)!);
      return;
    }
    
    // API-Call + Caching
    console.log('üåê ElevenLabs API:', emotionalText);
    const audioBuffer = await this.generateSpeech(emotionalText);
    this.audioCache.set(cacheKey, audioBuffer);
    
    await this.playAudio(audioBuffer);
  }
  
  private hashText(text: string): string {
    return btoa(text).slice(0, 20); // Simple hash f√ºr Cache-Key
  }
  
  // Diagnose-Methoden
  getCacheStats(): { size: number; keys: string[] } {
    return {
      size: this.audioCache.size,
      keys: Array.from(this.audioCache.keys())
    };
  }
}
```

### **Phase 3: Integration in bestehende Navigation (1-2 Stunden)**

#### 3.1 Hook-Integration
```typescript
// client/src/hooks/useNavigation.ts (erweitert)
import { EnhancedElevenLabsVoice } from '../services/elevenLabsVoice';

export function useNavigation() {
  // Bestehende Navigation-Logic...
  const [voiceManager] = useState(() => new EnhancedElevenLabsVoice());
  const [voiceEnabled, setVoiceEnabled] = useState(false);
  
  // Voice-Ansagen bei Navigation-Updates
  useEffect(() => {
    if (!voiceEnabled || !currentInstruction) return;
    
    const announceInstruction = async () => {
      try {
        // Bestimme Ansage-Typ basierend auf Instruction
        const type = currentInstruction.includes('Ziel erreicht') ? 'arrival' :
                    currentInstruction.includes('Achtung') ? 'warning' : 'direction';
        
        await voiceManager.speakNavigation(currentInstruction, type);
      } catch (error) {
        console.error('Voice announcement failed:', error);
      }
    };
    
    announceInstruction();
  }, [currentInstruction, voiceEnabled]);
  
  return {
    // Bestehende Returns...
    voiceEnabled,
    setVoiceEnabled,
    voiceManager, // F√ºr Debug-Zwecke
  };
}
```

#### 3.2 UI-Controls
```typescript
// client/src/components/Navigation/VoiceControls.tsx
interface VoiceControlsProps {
  voiceEnabled: boolean;
  onVoiceToggle: (enabled: boolean) => void;
  voiceManager: EnhancedElevenLabsVoice;
}

export function VoiceControls({ voiceEnabled, onVoiceToggle, voiceManager }: VoiceControlsProps) {
  const [cacheStats, setCacheStats] = useState(voiceManager.getCacheStats());
  
  const updateCacheStats = () => {
    setCacheStats(voiceManager.getCacheStats());
  };
  
  const testQuickAnnouncement = async () => {
    await voiceManager.speakNavigation("Auf Geilenkirchener Stra√üe geradeaus fahren");
    updateCacheStats();
  };
  
  return (
    <div className="bg-gray-50 p-3 rounded-lg">
      <div className="flex items-center justify-between mb-3">
        <label className="text-sm font-medium">üé§ Deutsche Sprachf√ºhrung</label>
        <button
          onClick={() => onVoiceToggle(!voiceEnabled)}
          className={`w-12 h-6 rounded-full transition-colors ${
            voiceEnabled ? 'bg-blue-500' : 'bg-gray-300'
          }`}
        >
          <div className={`w-5 h-5 bg-white rounded-full transition-transform ${
            voiceEnabled ? 'translate-x-6' : 'translate-x-1'
          }`} />
        </button>
      </div>
      
      <button
        onClick={testQuickAnnouncement}
        className="w-full p-2 bg-blue-100 hover:bg-blue-200 rounded text-sm"
      >
        üéØ Test deutsche Ansage
      </button>
      
      {/* Debug Info */}
      <div className="mt-2 text-xs text-gray-600">
        Cache: {cacheStats.size} Ansagen gespeichert
      </div>
    </div>
  );
}
```

### **Phase 4: Testing & Debugging (2-3 Stunden)**

#### 4.1 Comprehensive Testing
```typescript
// client/src/components/Navigation/ElevenLabsDebugPanel.tsx
export function ElevenLabsDebugPanel() {
  const [apiStatus, setApiStatus] = useState<'unknown' | 'working' | 'error'>('unknown');
  const [testResults, setTestResults] = useState<string[]>([]);
  
  const germanTestCases = [
    "Links abbiegen",
    "Rechts abbiegen", 
    "Geradeaus fahren",
    "Auf Geilenkirchener Stra√üe geradeaus fahren",
    "Rechts abbiegen auf Fasanenstra√üe",
    "Links abbiegen in den Kirchplatz",
    "In 200 Metern rechts abbiegen",
    "Sie haben Ihr Ziel erreicht"
  ];
  
  const runComprehensiveTest = async () => {
    const voiceManager = new EnhancedElevenLabsVoice();
    const results: string[] = [];
    
    for (const testCase of germanTestCases) {
      try {
        const startTime = Date.now();
        await voiceManager.speakNavigation(testCase);
        const duration = Date.now() - startTime;
        
        results.push(`‚úÖ "${testCase}" - ${duration}ms`);
      } catch (error) {
        results.push(`‚ùå "${testCase}" - Fehler: ${error}`);
      }
    }
    
    setTestResults(results);
    setApiStatus('working');
  };
  
  return (
    <div className="bg-white p-4 rounded-lg shadow">
      <h3 className="text-lg font-semibold mb-4">üîß ElevenLabs Debug Panel</h3>
      
      <button
        onClick={runComprehensiveTest}
        className="w-full p-3 bg-green-500 text-white rounded hover:bg-green-600 mb-4"
      >
        üß™ Vollst√§ndiger Test aller deutschen Ansagen
      </button>
      
      <div className="space-y-1">
        {testResults.map((result, index) => (
          <div key={index} className="text-sm font-mono bg-gray-50 p-2 rounded">
            {result}
          </div>
        ))}
      </div>
    </div>
  );
}
```

#### 4.2 Real-World Navigation Test
```typescript
// Test-Route f√ºr Zuhause/Gangelt
const testRoute = {
  instructions: [
    "Navigation gestartet",
    "Auf Geilenkirchener Stra√üe geradeaus fahren", 
    "In 300 Metern rechts abbiegen",
    "Rechts abbiegen auf Fasanenstra√üe",
    "Links abbiegen in den Kirchplatz",
    "In 100 Metern haben Sie Ihr Ziel erreicht",
    "Sie haben Ihr Ziel erreicht"
  ]
};

// Integration in bestehende Navigation f√ºr Live-Test
```

### **Phase 5: Performance-Optimierung (1 Stunde)**

#### 5.1 Preloading h√§ufiger Ansagen
```typescript
// H√§ufige Navigation-Ansagen vorloaden
const commonInstructions = [
  "Links abbiegen",
  "Rechts abbiegen", 
  "Geradeaus fahren",
  "Sie haben Ihr Ziel erreicht"
];

// Beim App-Start preloaden
useEffect(() => {
  if (voiceEnabled) {
    commonInstructions.forEach(instruction => {
      voiceManager.speakNavigation(instruction); // Cached f√ºr sp√§ter
    });
  }
}, [voiceEnabled]);
```
